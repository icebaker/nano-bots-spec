# Nano Bots

![Nano Bot](https://user-images.githubusercontent.com/113217272/237534390-3f0e0dc7-1f92-4490-a12d-bfc9d145cddb.png)
_Image artificially created by Midjourney through a prompt generated by a Nano Bot specialized in Midjourney._

**Nano Bots** is an open specification that can be implemented in any programming language. It specifies a configuration file with human-readable instructions for creating small and specialized AI-powered bots that can be effortlessly shared as a single, lightweight file.

Here's what a Nano Bot _Cartridge_ looks like:

```yaml
---
name: Assistant
version: 0.0.1

behaviors:
  interaction:
    directive: You are a helpful assistant.

interfaces:
  repl:
    prompt:
      - text: ''
      - text: '> '
        color: blue

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

Here's what a fully-functional implementation of Nano Bots feels like:

```bash
nano-bot to-en-us-translator.yml eval "Salut, comment 癟a va?"
# => Hello, how are you doing?

nano-bot midjourney.yml eval "happy and friendly cyberpunk robot"
# => The robot exploring a bustling city, surrounded by neon lights
#    and high-rise buildings. The prompt should include colorful
#    lighting and a sense of excitement in the facial expression.

nano-bot lisp.yml eval "(+ 1 2)"
# => 3

cat article.txt |
  nano-bot to-en-us-translator.yml eval |
  nano-bot summarizer.yml eval
# -> LLM stands for Large Language Model, which refers to an
#    artificial intelligence algorithm capable of processing
#    and understanding vast amounts of natural language data,
#    allowing it to generate human-like responses and perform
#    a range of language-related tasks.
```

```bash
nano-bot assistant.yml repl
```

```text
> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

> |
```

## Rationale

While Artificial Intelligence and Large Language Models continue to evolve with increasingly larger and more complex projects emerging, Nano Bots takes a different approach. It focuses on creating smaller, specialized bots inspired by the [Unix philosophy](https://en.wikipedia.org/wiki/Unix_philosophy), which emphasizes simplicity, modularity, and composability in software design:

- Simplicity: Each Nano Bot focuses on a single task or domain, resulting in more efficient and manageable bots.

- Modularity: Nano Bots are designed as independent and self-contained modules, each responsible for a specific functionality. This allows for easier development, testing, and maintenance.

- Composability: Inspired by the [Unix pipeline](https://en.wikipedia.org/wiki/Pipeline_(Unix)), Nano Bots can be combined and composed to create more complex AI workflows, allowing users to tailor AI solutions to their needs without relying on monolithic projects.

## Definition

A **Nano Bot** is a cohesive combination of a `cartridge` [YAML](https://yaml.org) file, an `implementation`, and a `provider`.

The `cartridge` YAML file contains human-readable data that outlines the bot's goals, expected behaviors, and settings for authentication and provider utilization.

The `implementation` processes the YAML _cartridge_ file, comprehending its instructions, and interacts with the `provider`'s AI Service to enable the bot to perform the expected behavior.

Together, these components create a fully functional **Nano Bot**:

```text
Nano Bot = (cartridge.yml + implementation + provider)
```

# Cartridges

![Cartridges](https://user-images.githubusercontent.com/113217272/237534411-61cd7610-5a8c-4294-8840-559a1c58c603.png)
_Image artificially created by Midjourney through a prompt generated by a Nano Bot specialized in Midjourney._

A cartridge (inspired by _[Game ROM Cartridges](https://en.wikipedia.org/wiki/ROM_cartridge)_) should contain all the information required for a Nano Bot to be functional in any implementation of this specification.

Here is a minimal sample of a cartridge [YAML](https://yaml.org) file:

```yaml
---
name: Assistant
version: 0.0.1

behaviors:
  interaction:
    directive: You are a helpful assistant.

interfaces:
  repl:
    prompt:
      - text: ''
      - text: '> '
        color: blue

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

## Behaviors

The `behaviors:` section provides information to influence the expected behavior of the bot. There are three types of concepts that can influence a behavior:


- `directive` communicates about how the bot should behave and aligns with the concept of a rule or guideline.
- `backdrop` sets the stage and provides contextual information to help the bot understand the situation and respond accordingly.
- `instruction` implies a direct command about what the bot should do next, it represents a specific action that the bot is expected to perform.

Sample of a behaviors section:

```yaml
---
behaviors:
  interaction:
    directive: You are a helpful assistant.
    backdrop: |
      The Moon is Earth's natural satellite, orbiting our planet.
      The user might use the term "Selene" when referring to the Moon.
  boot:
    directive: You are a helpful assistant.
    instruction: Provide a welcome message.
```

- `interaction:` is used when users directly interact with the Nano Bot through _REPL_ or _Eval_.
- `boot:` is used when the Nano Bot starts in interfaces that support an initial boot message, like _REPL_.

### Directive

```yaml
---
behaviors:
  interaction:
    directive: You are a helpful assistant.
```

A `directive` serves as a guideline for how the bot is expected to behave, also known as _system messages_. Some non-exhaustive examples of directives include:

```text
You are a helpful assistant.
```

```text
You are an AI assistant that responds strictly in JSON format for all answers.
```

```text
You are a helpful assistant that specializes in providing information about historical events.
```

```text
You are a programming tutor, helping users learn and troubleshoot code in various programming languages.
```

```text
You are an AI personality emulator that responds to all questions in the style of Shakespeare.
```

### Backdrop

```yaml
---
behaviors:
  interaction:
    backdrop: |
      The Moon is Earth's natural satellite, orbiting our planet.
      The user might use the term "Selene" when referring to the Moon.
```

Backdrop provides contextual information to help the bot understand the situation and respond appropriately. This may involve sharing examples of expected responses, supplying information the bot needs to learn before answering, among other strategies.

### Instruction

```yaml
---
behaviors:
  boot:
    instruction: Provide a welcome message.
```

An `instruction` is a clear and concise directive given to the bot, intended to guide it in performing a particular action or task.

## Interfaces

Implementations should support two possible interaction interfaces: REPL and Eval.

### REPL

```yaml
---
interfaces:
  repl:
    stream: true
    prefix: "\n"
    postfix: "\n"
    prompt:
      - text: ''
      - text: '> '
        color: blue
```

A Read-Eval-Print Loop (REPL) is a streamlined interactive programming environment that allows users to input individual commands, processes them, and returns the results to the user in real-time.

An implementation may opt to build its REPL from scratch or leverage existing technologies such as [nREPL](https://github.com/nrepl/nrepl), [Pry](https://github.com/pry/pry), [SLIME](https://slime.common-lisp.dev), [IPython](https://github.com/ipython/ipython), [LSP](https://microsoft.github.io/language-server-protocol/), [Jupyter Notebook](https://github.com/jupyter/notebook), etc.

An implementation would likely provide access to the REPL as follows:
```bash
nano-bot assistant.yml repl
```

This is an example of a functioning REPL based on the previous YAML fragment:

```text
> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

> I like the color pink.

That's great to hear! Is there anything related to the color pink that you
would like to know or need assistance with?

> What color do I like?

Based on your previous statement, you mentioned that you like the color
pink. So, it can be assumed that you like the color pink. Is there
anything related to the color pink you need help with?

> |
```

#### State

A REPL should be capable of maintaining a conversation, which means that throughout its lifetime, it needs to retain the conversation history and utilize it during interactions.

#### Boot

If specified in the cartridge YAML, a REPL should display a boot message:

```yaml
---
behaviors:
  boot:
    directive: You are a helpful assistant.
    instruction: Provide a welcome message.
```

```text
Hello and welcome! As your virtual assistant, I am here to assist you with
any questions or tasks you may have. Please don't hesitate to ask me anything.
I am here to make your life easier and more efficient.

> |
```

#### Stream

If specified in the cartridge YAML and supported by the provider, the REPL should be capable of streaming messages in parts (characters or words).

### Eval

Eval (short for evaluation) refers to single-turn executions of the Nano Bot that, when given an input, produce an output.

An implementation would likely provide access to eval as follows:
```bash
nano-bot assistant.yml eval "What is the distance to the Moon?"
```

```text
The average distance between the Earth and the Moon
is about 238,855 miles (384,400 kilometers).
```

Evaluation executions do not provide boot messages and are stateless.

Implementations should also be capable of receiving input from [standard streams](https://en.wikipedia.org/wiki/Standard_streams), allowing execution with [pipe operators](https://en.wikipedia.org/wiki/Pipeline_(Unix)):

```bash
echo "What is the distance to the Moon?" | nano-bot assistant.yml eval
```

```text
The average distance from the Earth to the Moon
is about 238,855 miles (384,400 kilometers).
```

#### Stream

If specified in the cartridge YAML and supported by the provider, the evaluation should be capable of streaming messages in parts (characters or words).

## Providers

Nano Bots should be **provider-agnostic**, which means that the same Nano Bot should be able to run on different providers.

Examples of popular providers include: [Vicuna](https://github.com/lm-sys/FastChat), [Open AI](https://platform.openai.com/docs/api-reference), [Google Bard](https://bard.google.com), [Alpaca](https://github.com/tatsu-lab/stanford_alpaca), and [LLaMA](https://github.com/facebookresearch/llama).

The `provider:` section of the cartridge should specify the provider's `name`, followed by a `settings` section containing relevant information that enables the Nano Bot to interact with the provider, adhering to the provider's API expected settings.

Minimal sample of a provider section:

```yaml
---
provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

### Credentials

Although it is possible to set credentials directly in the cartridge YAML, it is important to consider that cartridges may be widely shared, and exposing your credentials poses a security risk. Therefore, it is recommended to use environment variables for credentials.

Implementations should apply the regular expression `^ENV.` and replace data with prefixes like `ENV/` or `ENV-` with the corresponding environment variable value. For example, `ENV/OPENAI_API_ACCESS_TOKEN` should load the environment variable `OPENAI_API_ACCESS_TOKEN`.

### Open AI

API Documentation: https://platform.openai.com/docs/api-reference

```yaml
---
provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    stream: true
    temperature: 1
    top_p: 1
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

# Implementations

Nano Bots can be implemented in any programming language. Typically, implementations provide executable binaries capable of interpreting the cartridge YAML file as specified here, correctly interacting with multiple providers, and offering the expected interaction interfaces (_REPL_ and _Eval_).

Here's what a fully-functional implementation of Nano Bots feels like:

```bash
nano-bot to-en-us-translator.yml eval "Salut, comment 癟a va?"
# => Hello, how are you doing?

nano-bot midjourney.yml eval "happy and friendly cyberpunk robot"
# => The robot exploring a bustling city, surrounded by neon lights
#    and high-rise buildings. The prompt should include colorful
#    lighting and a sense of excitement in the facial expression.

nano-bot lisp.yml eval "(+ 1 2)"
# => 3

cat article.txt |
  nano-bot to-en-us-translator.yml eval |
  nano-bot summarizer.yml eval
# -> LLM stands for Large Language Model, which refers to an
#    artificial intelligence algorithm capable of processing
#    and understanding vast amounts of natural language data,
#    allowing it to generate human-like responses and perform
#    a range of language-related tasks.
```

```bash
nano-bot assistant.yml repl
```

```text
> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

> |
```

You may name your binary as you wish, with `nano-bot` being just an illustrative example.
