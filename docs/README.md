# Nano Bots

![Nano Bot](https://user-images.githubusercontent.com/113217272/237534390-3f0e0dc7-1f92-4490-a12d-bfc9d145cddb.png)
_Image artificially created by Midjourney through a prompt generated by a Nano Bot specialized in Midjourney._

**Nano Bots** is an open specification that can be implemented in any programming language. It specifies a configuration file with human-readable instructions for creating small and specialized AI-powered bots that can be effortlessly shared as a single, lightweight file.

Here's what a Nano Bot _Cartridge_ looks like:

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.

behaviors:
  interaction:
    directive: You are a helpful assistant.

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

Here's what a fully-functional implementation of Nano Bots feels like:

```bash
nb - - eval "hello"
# => Hello! How may I assist you today?

nb to-en-us-translator.yml - eval "Salut, comment √ßa va?"
# => Hello, how are you doing?

nb midjourney.yml - eval "happy cyberpunk robot"
# => A cheerful and fun-loving robot is dancing wildly amidst a
#    futuristic and lively cityscape. Holographic advertisements
#    and vibrant neon colors can be seen in the background.

nb lisp.yml - eval "(+ 1 2)"
# => 3

cat article.txt |
  nb to-en-us-translator.yml - eval |
  nb summarizer.yml - eval
# -> LLM stands for Large Language Model, which refers to an
#    artificial intelligence algorithm capable of processing
#    and understanding vast amounts of natural language data,
#    allowing it to generate human-like responses and perform
#    a range of language-related tasks.
```

```bash
nb - - repl

nb assistant.yml - repl
```

```text
ü§ñ> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

ü§ñ> |
```

## Rationale

While Artificial Intelligence and Large Language Models continue to evolve with increasingly larger and more complex projects emerging, Nano Bots takes a different approach. It focuses on creating smaller, specialized bots inspired by the [Unix philosophy](https://en.wikipedia.org/wiki/Unix_philosophy), which emphasizes simplicity, modularity, and composability in software design:

- Simplicity: Each Nano Bot focuses on a single task or domain, resulting in more efficient and manageable bots.

- Modularity: Nano Bots are designed as independent and self-contained modules, each responsible for a specific functionality. This allows for easier development, testing, and maintenance.

- Composability: Inspired by the [Unix pipeline](https://en.wikipedia.org/wiki/Pipeline_(Unix)), Nano Bots can be combined and composed to create more complex AI workflows, allowing users to tailor AI solutions to their needs without relying on monolithic projects.

## Definition

A **Nano Bot** is a cohesive combination of a `cartridge` [YAML](https://yaml.org) file, an `implementation`, and a `provider`.

The `cartridge` YAML file contains human-readable data that outlines the bot's goals, expected behaviors, and settings for authentication and provider utilization.

The `implementation` processes the YAML _cartridge_ file, comprehending its instructions, and interacts with the `provider`'s AI Service to enable the bot to perform the expected behavior.

Together, these components create a fully functional **Nano Bot**:

```text
Nano Bot = (cartridge.yml + implementation + provider)
```

## Implementations

Implementations of this specification:

- [Nano Bots CLI (Ruby)](https://github.com/icebaker/ruby-nano-bots)

### Projects

- [Nano Bots CLI (Ruby)](https://github.com/icebaker/ruby-nano-bots)
- [Nano Bots Clinic (Live Editor)](https://clinic.nbots.io)
- [Nano Bots API](https://github.com/icebaker/nano-bots-api)
  - [Public API](https://api.nbots.io)
- [Nano Bots for Sublime Text](https://github.com/icebaker/sublime-nano-bots)
- [Nano Bots for Visual Studio Code](https://github.com/icebaker/vscode-nano-bots)

# Cartridges

![Cartridges](https://user-images.githubusercontent.com/113217272/237534411-61cd7610-5a8c-4294-8840-559a1c58c603.png)
_Image artificially created by Midjourney through a prompt generated by a Nano Bot specialized in Midjourney._

A cartridge (inspired by _[Game ROM Cartridges](https://en.wikipedia.org/wiki/ROM_cartridge)_) should contain all the information required for a Nano Bot to be functional in any implementation of this specification.

Here is a minimal sample of a cartridge [YAML](https://yaml.org) file:

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.

behaviors:
  interaction:
    directive: You are a helpful assistant.

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

## Meta

The `meta:` section provides basic information about the Cartridge.

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.
```

`symbol:` is a single [Unicode emoji character](https://home.unicode.org/emoji/about-emoji/).

`name:` and `author:` are single-line text values encouraged to be short.

`version:` must follow [Semantic Versioning 2.0.0](https://semver.org).

`license:` must comply with the [SPDX Identifier](https://spdx.dev/ids/).

`description:` is a brief text that details what to expect from the Nano Bot, encouraged to be concise.

### License

The classification of _prompts_ for Large Language Models as code, art, or intellectual property, as well as their applicability to licensing, intellectual property rights, copyright, or patenting, remain subjects of ongoing and complex debate without a clear answer or definitive understanding at present.

When Nano Bots expand prompt writing into a more detailed scheme and add small pieces of code like [adapters](?id=adapters), the debate becomes even trickier and blurrier.

Due to the complexities of this debate, we recommend that authors publish their creations under licenses. The recommended license, described in the examples, is [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/) to avoid confusion regarding the use of your Nano Bots by others. However, any [SPDX known license](https://spdx.org/licenses/) may be chosen.

Please note that we are uncertain if this approach is practical or enforceable, so it should not be considered a guarantee of licensing but rather a statement of your intention.

## Behaviors

The `behaviors:` section provides information to influence the expected behavior of the bot. There are three types of concepts that can influence a behavior:


- `directive` communicates about how the bot should behave and aligns with the concept of a rule or guideline.
- `backdrop` sets the stage and provides contextual information to help the bot understand the situation and respond accordingly.
- `instruction` implies a direct command about what the bot should do next, it represents a specific action that the bot is expected to perform.

Sample of a behaviors section:

```yaml
---
behaviors:
  interaction:
    directive: You are a helpful assistant.
    backdrop: |
      The Moon is Earth's natural satellite, orbiting our planet.
      The user might use the term "Selene" when referring to the Moon.
  boot:
    directive: You are a helpful assistant.
    instruction: Provide a welcome message.
```

- `interaction:` is used when users directly interact with the Nano Bot through _REPL_ or _Eval_.
- `boot:` is used when the Nano Bot starts in interfaces that support an initial boot message, like _REPL_.

### Directive

```yaml
---
behaviors:
  interaction:
    directive: You are a helpful assistant.
```

A `directive` serves as a guideline for how the bot is expected to behave, also known as _system messages_. Some non-exhaustive examples of directives include:

```text
You are a helpful assistant.
```

```text
You are an AI assistant that responds strictly in JSON format for all answers.
```

```text
You are a helpful assistant that specializes in providing information about historical events.
```

```text
You are a programming tutor, helping users learn and troubleshoot code in various programming languages.
```

```text
You are an AI personality emulator that responds to all questions in the style of Shakespeare.
```

### Backdrop

```yaml
---
behaviors:
  interaction:
    backdrop: |
      The Moon is Earth's natural satellite, orbiting our planet.
      The user might use the term "Selene" when referring to the Moon.
```

Backdrop provides contextual information to help the bot understand the situation and respond appropriately. This may involve sharing examples of expected responses, supplying information the bot needs to learn before answering, among other strategies.

### Instruction

```yaml
---
behaviors:
  boot:
    instruction: Provide a welcome message.
```

An `instruction` is a clear and concise directive given to the bot, intended to guide it in performing a particular action or task.

## Interfaces

Implementations should support two possible interaction interfaces: REPL and Eval.

You can customize both the _input_ and _output_ with prefixes, suffixes, and adapters for all interfaces:

```yaml
---
interfaces:
  input:
    prefix: "\n"
    suffix: "\n"
    adapter:
      fennel: |
        (.. "```" content "```")
      lua: |
        "```" .. content .. "```"
  output:
    stream: true
    prefix: "\n"
    suffix: "\n"
    adapter:
      fennel: |
        (.. "```" content "```")
      lua: |
        "```" .. content .. "```"
```

### REPL

```yaml
---
interfaces:
  repl:
    input:
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    output:
      stream: true
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    prompt:
      - text: 'ü§ñ'
      - text: '> '
```

A Read-Eval-Print Loop (REPL) is a streamlined interactive programming environment that allows users to input individual commands, processes them, and returns the results to the user in real-time.

An implementation may opt to build its REPL from scratch or leverage existing technologies such as [nREPL](https://github.com/nrepl/nrepl), [Pry](https://github.com/pry/pry), [SLIME](https://slime.common-lisp.dev), [IPython](https://github.com/ipython/ipython), [LSP](https://microsoft.github.io/language-server-protocol/), [Jupyter Notebook](https://github.com/jupyter/notebook), etc.

An implementation would likely provide access to the REPL as follows:
```bash
nb assistant.yml - repl
```

This is an example of a functioning REPL based on the following YAML fragment:

```yaml
---
interfaces:
  repl:
    output:
      prefix: "\n"
      suffix: "\n"
    prompt:
      - text: 'ü§ñ'
      - text: '> '
```

```text
ü§ñ> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

ü§ñ> I like the color pink.

That's great to hear! Is there anything related to the color pink that you
would like to know or need assistance with?

ü§ñ> What color do I like?

Based on your previous statement, you mentioned that you like the color
pink. So, it can be assumed that you like the color pink. Is there
anything related to the color pink you need help with?

ü§ñ> |
```

#### Boot

If specified in the cartridge YAML, a REPL should display a boot message:

```yaml
---
behaviors:
  boot:
    directive: You are a helpful assistant.
    instruction: Provide a welcome message.
```

```text
Hello and welcome! As your virtual assistant, I am here to assist you with
any questions or tasks you may have. Please don't hesitate to ask me anything.
I am here to make your life easier and more efficient.

ü§ñ> |
```

#### Prompt

You can personalize your prompt using an array of texts, with optional color formatting available for each element:

```yaml
---
interfaces:
  repl:
    prompt:
      - text: üíÄ
      - text: '‚ûú '
        color: deeppink
```

You have the option to utilize [ANSI colors](https://github.com/sickill/rainbow#ansi-colors) such as `blue`, `magenta`, and so on, or [X11 colors](https://github.com/sickill/rainbow#x11-colors) such as `aquamarine`, `deeppink`, and so forth.

The previous fragment would result in the following prompt:


> <span>üíÄ</span><span style="color: #ff00af;">‚ûú</span> |

### Eval

```yaml
---
interfaces:
  eval:
    input:
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    output:
      stream: true
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
```

Eval (short for evaluation) refers to single-turn executions of the Nano Bot that, when given an input, produce an output.

An implementation would likely provide access to eval as follows:
```bash
nb assistant.yml - eval "What is the distance to the Moon?"
```

```text
The average distance between the Earth and the Moon
is about 238,855 miles (384,400 kilometers).
```

Evaluation executions do not provide boot messages.

Implementations should also be capable of receiving input from [standard streams](https://en.wikipedia.org/wiki/Standard_streams), allowing execution with [pipe operators](https://en.wikipedia.org/wiki/Pipeline_(Unix)):

```bash
echo "What is the distance to the Moon?" | nb assistant.yml - eval
```

```text
The average distance from the Earth to the Moon
is about 238,855 miles (384,400 kilometers).
```

### Adapters

Adapters are simple and small pieces of code that can manipulate inputs and outputs. Implementations should support two languages for adapters: [Lua](https://www.lua.org/about.html) and [Fennel](https://fennel-lang.org). 

Both languages are simple, extremely lightweight, and fast. They are widely available and supported by multiple platforms and operating systems, and can be easily embedded into any programming language.

```yaml
---
adapter:
  fennel: |
    (.. "```" content "```")
```

```yaml
---
adapter:
  lua: |
    "```" .. content .. "```"
```

Adapters have access to a `content` variable that holds either the user's input or the Nano Bot's output.

Output adapters are only activated when the stream functionality is not enabled.

Regarding input, the prefix, suffix, and any modifications made by the adapter are sent to the bot. If the interaction is not stateless, these elements are also preserved in the state history.

In contrast, for outputs, any changes made by the adapter, prefix, and suffix aren't saved or used in later messages to the bot. These changes are used only for displaying purposes or for pipeline operations.

## Providers

Nano Bots should be **provider-agnostic**, which means that the same Nano Bot should be able to run on different providers.

Examples of popular providers include: [Vicuna](https://github.com/lm-sys/FastChat), [Open AI](https://platform.openai.com/docs/api-reference), [Google PaLM](https://developers.generativeai.google), [Alpaca](https://github.com/tatsu-lab/stanford_alpaca), and [LLaMA](https://github.com/facebookresearch/llama).

The `provider:` section of the cartridge should specify the provider's `name`, followed by a `settings` section containing relevant information that enables the Nano Bot to interact with the provider, adhering to the provider's API expected settings.

Minimal sample of a provider section:

```yaml
---
provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

### Credentials

Although it is possible to set credentials directly in the cartridge YAML, it is important to consider that cartridges may be widely shared, and exposing your credentials poses a security risk. Therefore, it is recommended to use environment variables for credentials.

Implementations should apply the regular expression `^ENV.` and replace data with prefixes like `ENV/` or `ENV-` with the corresponding environment variable value. For example, `ENV/OPENAI_API_ACCESS_TOKEN` should load the environment variable `OPENAI_API_ACCESS_TOKEN`.

### Open AI

API Documentation: https://platform.openai.com/docs/api-reference

```yaml
---
provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    stream: true
    temperature: 1
    top_p: 1
    n: 1
    stop: null
    max_tokens: null
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: null
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
      # https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids
```

## Miscellaneous

```yaml
---
miscellaneous:
  key: value
```

`miscellaneous:` is an optional key that can hold additional data for purposes other than making the Nano Bot functional. This data may include metadata for marketplaces, educational information, and so on. It's important to note that these keys must be not relevant for the Nano Bot's operation and should be deliberately ignored by implementations.

They can contain any information or structure, as shown in the following examples:

```yaml
---
miscellaneous:
  some-marketplace:
    background-color: blue
    tags:
      - creativity
      - programming
```

```yaml
---
miscellaneous:
  some-platform:
    technique: summarization
    details: |
      This Nano Bot exemplifies one of the
      common approaches to summarizing content.
```

# Implementations

Nano Bots can be implemented in any programming language. Typically, implementations provide executable binaries capable of interpreting the cartridge YAML file as specified here, correctly interacting with multiple providers, and offering the expected interaction interfaces (_REPL_ and _Eval_).

Here's what a fully-functional implementation of Nano Bots feels like:

```bash
nb - - eval "hello"
# => Hello! How may I assist you today?

nb to-en-us-translator.yml - eval "Salut, comment √ßa va?"
# => Hello, how are you doing?

nb midjourney.yml - eval "happy cyberpunk robot"
# => A cheerful and fun-loving robot is dancing wildly amidst a
#    futuristic and lively cityscape. Holographic advertisements
#    and vibrant neon colors can be seen in the background.

nb lisp.yml - eval "(+ 1 2)"
# => 3

cat article.txt |
  nb to-en-us-translator.yml - eval |
  nb summarizer.yml - eval
# -> LLM stands for Large Language Model, which refers to an
#    artificial intelligence algorithm capable of processing
#    and understanding vast amounts of natural language data,
#    allowing it to generate human-like responses and perform
#    a range of language-related tasks.
```

```bash
nb - - repl

nb assistant.yml - repl
```

```text
ü§ñ> Hi, how are you doing?

As an AI language model, I do not experience emotions but I am functioning
well. How can I assist you?

ü§ñ> |
```

You may name your binary as you wish, with `nb` being just an illustrative example.

## Cartridges

Cartridges are YML files and should be loaded according to the path specified by the user:

```bash
nb assistant.yml - repl
```

This command should attempt to load the `assistant.yml` file. The user may omit the file extension:

```bash
nb assistant - repl
```

In this case, the implementation should attempt to load either the `assistant.yml` or `assistant.yaml` file.

If the environment variable `NANO_BOTS_CARTRIDGES_DIRECTORY` is defined and the path was not found in the command's working directory, the implementation should attempt to load the file from the path specified in the environment variable:

```bash
NANO_BOTS_CARTRIDGES_DIRECTORY=/home/user/cartridges

nb assistant - repl
```

Paths that should be attempted to be loaded:


```text
/home/user/cartridges/assistant
/home/user/cartridges/assistant.yml
/home/user/cartridges/assistant.yaml
```

If no file is found, the implementation should fallback to attempting to load from the default expected cartridges directory, adhering to the [XDG specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html):


```text
/home/user/.local/share/nano-bots/cartridges/assistant
/home/user/.local/share/nano-bots/cartridges/assistant.yml
/home/user/.local/share/nano-bots/cartridges/assistant.yaml
```

### Default

This is the minimum required Cartridge data:

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

These are the default values when the following keys are not specified in the Cartridge file:

```yaml
---
interfaces:
  repl:
    output:
      stream: true
      suffix: "\n"
      prefix: "\n"
    prompt:
      - text: 'ü§ñ'
      - text: '> '
  eval:
    output:
      stream: true
      suffix: "\n"

provider:
  settings:
    stream: true
```

Users may choose not to provide a Cartridge file by using the `-` character:

```sh
nb - - repl
nb - - eval "Hi"
```

Under this circumstance, the implementation should apply the following default Cartridge:

```yaml
---
meta:
  symbol: ü§ñ
  name: Unknown
  author: None
  version: 0.0.0
  license: CC0-1.0
  description: Unknown

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
```

### Full Specification

This example showcases all the possible keys present in a Nano Bot Cartridge YAML file:

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.

behaviors:
  interaction:
    directive: You are a helpful assistant.
    backdrop: |
      The Moon is Earth's natural satellite, orbiting our planet.
      The user might use the term "Selene" when referring to the Moon.
    instruction: Answer the user's questions.
  boot:
    directive: You are a helpful assistant.
    backdrop: |
      This is a good example of a welcome message:
      "Welcome! How may I assist you?"
    instruction: Provide a welcome message.

interfaces:
  input:
    prefix: "\n"
    suffix: "\n"
    adapter:
      fennel: |
        (.. "```" content "```")
      lua: |
        "```" .. content .. "```"
  output:
    stream: true
    prefix: "\n"
    suffix: "\n"
    adapter:
      fennel: |
        (.. "```" content "```")
      lua: |
        "```" .. content .. "```"
  repl:
    input:
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    output:
      stream: true
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    prompt:
      - text: 'ü§ñ'
      - text: '> '
        color: blue
  eval:
    input:
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"
    output:
      stream: true
      prefix: "\n"
      suffix: "\n"
      adapter:
        fennel: |
          (.. "```" content "```")
        lua: |
          "```" .. content .. "```"

state:
  directory: ENV/NANO_BOTS_STATE_DIRECTORY

provider:
  name: openai
  settings:
    model: gpt-3.5-turbo
    stream: true
    temperature: 1
    top_p: 1
    n: 1
    stop: null
    max_tokens: null
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: null
    credentials:
      address: ENV/OPENAI_API_ADDRESS
      access-token: ENV/OPENAI_API_ACCESS_TOKEN
      user-identifier: ENV/OPENAI_API_USER_IDENTIFIER
      # https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids

miscellaneous:
  key: value
```

## State

### Stateless

By default, Nano Bots are stateless.

An evaluation is a single-turn interaction.

A REPL should be capable of maintaining multi-turn interactions, which means it must retain the conversation history and utilize it during interactions throughout its lifetime. Once the user exits the REPL, all history are discarded.

The default stateless behavior is defined by the `-` character in interactions:

```bash
nb assistant.yml - repl
nb assistant.yml - eval "Hi"
```

### Stateful

Implementations should support storing state by identifying a state key different from `-`:

```bash
nb assistant.yml E15D repl
nb assistant.yml D9D6 eval "Hi"
```

In this example, both `E15D` and `D9D6` are distinct identifiers used to indicate which state key should be employed for storing and retrieving state information related to that interaction.

In this scenario, both Eval and REPL store their states (history) and should be capable of performing multi-turn interactions. Eval will remember its previous interactions, and a REPL will remember its previous interactions even if it is exited and started again.

By default, implementations should be [XDG compliant](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html), which means that the default storage path would be:

```text
/home/user/.local/state/nano-bots/your-implementation
```

If the `NANO_BOTS_STATE_DIRECTORY` environment variable exists, it should be used as the directory to store the states.

A Cartridge may include a section that defines a custom directory for storing the states. In this case, it will override both the default and the path specified by the environment variable:

```yaml
---
state:
  directory: ENV/NANO_BOTS_STATE_DIRECTORY
```

The state should be stored in a manner that ensures isolation between multiple Nano Bots and Implementations.

In this example:

```bash
nb assistant.yml E15D repl
```

```yaml
---
meta:
  symbol: ü§ñ
  name: Nano Bot Name
  author: Your Name
  version: 1.0.0
  license: CC0-1.0
  description: A helpful assistant.

state:
  directory: /home/user/.local/state/nano-bots
```

The state should be stored in a path similar to this:

```text
/home/user/.local/state/nano-bots/your-implementation/your-name/nano-bot-name/0-0-1/E15D/state.json
```

JSON is merely an example; each implementation can choose the most suitable data format to work with.

> ‚ö†Ô∏è A Nano Bot should **never** depend on or rely on a state to function fully‚Äî**absolutely never**.

States serve as a convenience for users and should not be used to influence Nano Bot behaviors. Instead, such behaviors should be managed through the [Behaviors](?id=behaviors) section of the Cartridge YAML. This reinforces the notion that a Cartridge YAML file should ultimately be the sole and only necessary information for the bot to operate as expected.

## Stream

Unless otherwise specified in the Cartridge file, or if not supported by the provider, both the REPL and Eval Interfaces should be capable of streaming messages. This means they should be able to display content partially, whether character by character, token by token, or word by word.
